{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using TigerGraph CoPilot for Document Question Answering\n",
    "\n",
    "This notebook demostrates how to use TigerGraph CoPilot (currently in Beta), an AI assistant for your TigerGraph databases. TigerGraph CoPilot enables you to ask questions in natural language about your document data stored in TigerGraph and get answers in a human-readable format. GraphRAG is a graph-based retrieval-augmented generation approach that is used to answer questions about the document data stored in TigerGraph. TigerGraph CoPilot is built to help users get started with GraphRAG and to provide a seamless experience for users to interact with their document data within TigerGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# We first create a connection to the database\n",
    "host = \"http://192.168.99.201\" #os.environ[\"HOST\"]\n",
    "username = os.getenv(\"USERNAME\", \"tigergraph\")\n",
    "password = os.getenv(\"PASS\", \"tigergraph\")\n",
    "conn = TigerGraphConnection(\n",
    "    host=host,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    gsPort=\"31409\"\n",
    ")\n",
    "\n",
    "# And then add CoPilot's address to the connection. This address\n",
    "# is the host's address where the CoPilot container is running.\n",
    "conn.ai.configureCoPilotHost(\"http://localhost:8000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Graph and Ingest Data\n",
    "\n",
    "We provide utilities to setup your TigerGraph database with a schema and load your desired documents. In this example, we are utilizing the pyTigerGraph documentation as our dataset. The documents are processed into a JSONL file of the following format:\n",
    "\n",
    "```json\n",
    "{\"url\": \"some_url_here\", \"content\": \"Text of the document\"}\n",
    "```\n",
    "\n",
    "The following code block will create a graph called `pyTigerGraphRAG` and load the documents into the graph. The schema that is created looks like this:\n",
    "\n",
    "![supportai_schema](../img/SupportAISchema.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The graph pyTigerGraphRAG is created.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.gsql(\"\"\"CREATE GRAPH pyTigerGraphRAG()\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.graphname = \"pyTigerGraphRAG\"\n",
    "#conn.getToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_name': 'http://192.168.99.201',\n",
       " 'schema_creation_status': '\"Using graph \\'pyTigerGraphRAG\\'\\\\nSuccessfully created schema change jobs: [add_supportai_schema].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_schema\\\\nDoing schema change on graph \\'pyTigerGraphRAG\\' (current version: 0)\\\\nTrying to add local vertex \\'DocumentChunk\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'Document\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'Concept\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'Entity\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'Relationship\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'DocumentCollection\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'Content\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'EntityType\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'Community\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local vertex \\'ResolvedEntity\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'HAS_CONTENT\\' and its reverse edge \\'reverse_HAS_CONTENT\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'IS_CHILD_OF\\' and its reverse edge \\'reverse_IS_CHILD_OF\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'IS_HEAD_OF\\' and its reverse edge \\'reverse_IS_HEAD_OF\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'HAS_TAIL\\' and its reverse edge \\'reverse_HAS_TAIL\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'DESCRIBES_RELATIONSHIP\\' and its reverse edge \\'reverse_DESCRIBES_RELATIONSHIP\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'DESCRIBES_ENTITY\\' and its reverse edge \\'reverse_DESCRIBES_ENTITY\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'CONTAINS_ENTITY\\' and its reverse edge \\'reverse_CONTAINS_ENTITY\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'MENTIONS_RELATIONSHIP\\' and its reverse edge \\'reverse_MENTIONS_RELATIONSHIP\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'IS_AFTER\\' and its reverse edge \\'reverse_IS_AFTER\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'HAS_CHILD\\' and its reverse edge \\'reverse_HAS_CHILD\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'HAS_RELATIONSHIP\\' and its reverse edge \\'reverse_HAS_RELATIONSHIP\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'CONTAINS_DOCUMENT\\' and its reverse edge \\'reverse_CONTAINS_DOCUMENT\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'ENTITY_HAS_TYPE\\' and its reverse edge \\'reverse_ENTITY_HAS_TYPE\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'RELATIONSHIP_TYPE\\' and its reverse edge \\'reverse_RELATIONSHIP_TYPE\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'RELATIONSHIP\\' and its reverse edge \\'reverse_RELATIONSHIP\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'RESOLVES_TO\\' and its reverse edge \\'reverse_RESOLVES_TO\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'RESOLVED_RELATIONSHIP\\' and its reverse edge \\'reverse_RESOLVED_RELATIONSHIP\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'IN_COMMUNITY\\' and its reverse edge \\'reverse_IN_COMMUNITY\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'LINKS_TO\\' and its reverse edge \\'reverse_LINKS_TO\\' to the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add local edge \\'HAS_PARENT\\' and its reverse edge \\'reverse_HAS_PARENT\\' to the graph \\'pyTigerGraphRAG\\'.\\\\n\\\\nGraph pyTigerGraphRAG updated to new version 1\\\\nValidating existing queries for graph pyTigerGraphRAG ...\\\\nThe job add_supportai_schema completes in 1.371 seconds!\\\\nLocal schema change succeeded.\"',\n",
       " 'index_creation_status': '\"Using graph \\'pyTigerGraphRAG\\'\\\\nSuccessfully created schema change jobs: [add_supportai_indexes].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_indexes\\\\nDoing schema change on graph \\'pyTigerGraphRAG\\' (current version: 1)\\\\nTrying to add index \\'doc_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Document\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'doc_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Document\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'doc_epoch_processing_indexepoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Document\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'doc_chunk_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'DocumentChunk\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'DocumentChunk\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'DocumentChunk\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'concept_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Concept\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'concept_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Concept\\' on the graph \\'pyTigerGraphRAG\\'.\\\\nTrying to add index \\'concept_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Concept\\' on the graph \\'pyTigerGraphRAG\\'.\\\\n\\\\nGraph pyTigerGraphRAG updated to new version 2\\\\nValidating existing queries for graph pyTigerGraphRAG ...\\\\nThe job add_supportai_indexes completes in 1.212 seconds!\\\\nLocal schema change succeeded.\"'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.initializeSupportAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = \"AKIARJ6KUJUIS7KJ27YO\"\n",
    "sec = \"swYmXU+4yZbXiYCMfwSFxrcS0hNiOd6nzYog6VCZ\"\n",
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"s3\",\n",
    "    data_source_config={\"aws_access_key\": access, \"aws_secret_key\": sec},\n",
    "    loader_config={\"doc_id_field\": \"url\", \"content_field\": \"content\"},\n",
    "    file_format=\"json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_4cc0b2115f754540b4543469612743f6',\n",
       " 'job_id': 'pyTigerGraphRAG.load_documents_content_json_4cc0b2115f754540b4543469612743f6.stream.SupportAI_pyTigerGraphRAG_bc71b650248d41df83eae15155c2bce5.1733184693598',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/pyTigerGraphRAG.load_documents_content_json_4cc0b2115f754540b4543469612743f6.stream.SupportAI_pyTigerGraphRAG_bc71b650248d41df83eae15155c2bce5.1733184693598'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.runDocumentIngest(res[\"load_job_id\"], res[\"data_source_id\"], \"s3://tg-documentation/pytg_current/pytg_current.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'submitted'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.forceConsistencyUpdate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Document Search Methods\n",
    "\n",
    "TigerGraph CoPilot provides multiple methods to search documents in the graph. The methods are:\n",
    "- **HNSW Overlap**: This method uses a combination of vector search and graph traversal to find the most relevant information to the query. It uses the HNSW algorithm to search the embeddings of documents, document chunks, entities, and relationships. These results serve as the starting point for the graph traversal. The graph traversal is used to find the most relevant information to the query.\n",
    "\n",
    "- **Vector Search**: This method uses the HNSW algorithm to search the embeddings of one of the document, document chunk, entity, or relationship vector indices. It returns the most relevant information to the query based on the embeddings. This method is what you would expect from a traditional vector RAG solution.\n",
    "\n",
    "- **Sibling Search**: This method is very similar to the Vector Search method, but it uses the sibling (IS_AFTER) relationships between document chunks to expand the context around the document chunk that is most relevant to the query. This method is useful when you want to get more context around the most relevant document chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I get a count of vertices in Python?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HNSW Index Overlap in Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"hnswoverlap\",\n",
    "                        method_parameters = {\"indices\": [\"Document\", \"DocumentChunk\", \"Entity\", \"Relationship\"],\n",
    "                                             \"top_k\": 2,\n",
    "                                             \"num_hops\": 2,\n",
    "                                             \"num_seen_min\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Chunk Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"vdb\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"withHyDE\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sibling Document Chunk Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.ai.searchDocuments(query,\n",
    "                        method=\"sibling\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"lookahead\": 3,\n",
    "                                           \"lookback\": 3,\n",
    "                                           \"withHyDE\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing LLM Generated Responses\n",
    "\n",
    "TigerGraph CoPilot provides a way to generate the response to the user's query using a LLM, based on the search results from the methods above. You can compare the responses generated by the LLM for each of the search methods to see which one is the most relevant to the user's query. In this example, we can see that the HNSW Overlap method generates the most relevant response to the user's query. While none of the responses were wrong, the HNSW Overlap method generated the most relevant response to the user's query, by suggesting to use the `getVertexCount()` function to get the number of vertices in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"hnswoverlap\",\n",
    "                        method_parameters = {\"indices\": [\"Document\", \"DocumentChunk\", \"Entity\", \"Relationship\"],\n",
    "                                             \"top_k\": 2,\n",
    "                                             \"num_hops\": 2,\n",
    "                                             \"num_seen_min\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"retrieved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"vdb\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"withHyDE\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"retrieved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = conn.ai.answerQuestion(query,\n",
    "                        method=\"sibling\",\n",
    "                        method_parameters={\"index\": \"DocumentChunk\",\n",
    "                                           \"top_k\": 5,\n",
    "                                           \"lookahead\": 3,\n",
    "                                           \"lookback\": 3,\n",
    "                                           \"withHyDE\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp[\"retrieved\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytg_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
