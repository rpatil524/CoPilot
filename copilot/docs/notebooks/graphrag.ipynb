{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# We first create a connection to the database\n",
    "host = os.environ[\"HOST\"]\n",
    "username = os.getenv(\"USERNAME\", \"tigergraph\")\n",
    "password = os.getenv(\"PASS\", \"tigergraph\")\n",
    "conn = TigerGraphConnection(\n",
    "    host=host,\n",
    "    username=username,\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The graph GraphRAG_pytgdocs is created.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname = \"GraphRAG_pytgdocs\"\n",
    "conn.gsql(\"\"\"CREATE GRAPH GraphRAG_pytgdocs()\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conn.getToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_name': 'https://algotesting.i.tgcloud.io',\n",
       " 'schema_creation_status': '\"Using graph \\'GraphRAG_pytgdocs\\'\\\\nSuccessfully created schema change jobs: [add_supportai_schema].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_schema\\\\nDoing schema change on graph \\'GraphRAG_pytgdocs\\' (current version: 0)\\\\nTrying to add local vertex \\'DocumentChunk\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Document\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Concept\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Entity\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Relationship\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'DocumentCollection\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Content\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Community\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'ResolvedEntity\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_CONTENT\\' and its reverse edge \\'reverse_HAS_CONTENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_CHILD_OF\\' and its reverse edge \\'reverse_IS_CHILD_OF\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_HEAD_OF\\' and its reverse edge \\'reverse_IS_HEAD_OF\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_TAIL\\' and its reverse edge \\'reverse_HAS_TAIL\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'DESCRIBES_RELATIONSHIP\\' and its reverse edge \\'reverse_DESCRIBES_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'DESCRIBES_ENTITY\\' and its reverse edge \\'reverse_DESCRIBES_ENTITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'CONTAINS_ENTITY\\' and its reverse edge \\'reverse_CONTAINS_ENTITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'MENTIONS_RELATIONSHIP\\' and its reverse edge \\'reverse_MENTIONS_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_AFTER\\' and its reverse edge \\'reverse_IS_AFTER\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_CHILD\\' and its reverse edge \\'reverse_HAS_CHILD\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_RELATIONSHIP\\' and its reverse edge \\'reverse_HAS_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'CONTAINS_DOCUMENT\\' and its reverse edge \\'reverse_CONTAINS_DOCUMENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RELATIONSHIP\\' and its reverse edge \\'reverse_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RESOLVES_TO\\' and its reverse edge \\'reverse_RESOLVES_TO\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RESOLVED_RELATIONSHIP\\' and its reverse edge \\'reverse_RESOLVED_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IN_COMMUNITY\\' and its reverse edge \\'reverse_IN_COMMUNITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'LINKS_TO\\' and its reverse edge \\'reverse_LINKS_TO\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_PARENT\\' and its reverse edge \\'reverse_HAS_PARENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\n\\\\nGraph GraphRAG_pytgdocs updated to new version 1\\\\nThe job add_supportai_schema completes in 1.845 seconds!\\\\nLocal schema change succeeded.\"',\n",
       " 'index_creation_status': '\"Using graph \\'GraphRAG_pytgdocs\\'\\\\nSuccessfully created schema change jobs: [add_supportai_indexes].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_indexes\\\\nDoing schema change on graph \\'GraphRAG_pytgdocs\\' (current version: 1)\\\\nTrying to add index \\'doc_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_epoch_processing_indexepoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\n\\\\nGraph GraphRAG_pytgdocs updated to new version 2\\\\nThe job add_supportai_indexes completes in 1.085 seconds!\\\\nLocal schema change succeeded.\"'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # And then add CoPilot's address to the connection. This address\n",
    "# # is the host's address where the CoPilot container is running.\n",
    "conn.ai.configureCoPilotHost(\"http://localhost:8000\")\n",
    "conn.ai.initializeSupportAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "sec = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"s3\",\n",
    "    data_source_config={\"aws_access_key\": access, \"aws_secret_key\": sec},\n",
    "    loader_config={\"doc_id_field\": \"url\", \"content_field\": \"content\"},\n",
    "    file_format=\"json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_cde7e4db979b4ba8a0b6ec5eb927f875',\n",
       " 'job_id': 'GraphRAG_pytgdocs.load_documents_content_json_cde7e4db979b4ba8a0b6ec5eb927f875.stream.SupportAI_GraphRAG_pytgdocs_48ee36da7b7644e4995722a6e057d446.1723494758507',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/GraphRAG_pytgdocs.load_documents_content_json_cde7e4db979b4ba8a0b6ec5eb927f875.stream.SupportAI_GraphRAG_pytgdocs_48ee36da7b7644e4995722a6e057d446.1723494758507'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.runDocumentIngest(\n",
    "    res[\"load_job_id\"],\n",
    "    res[\"data_source_id\"],\n",
    "    \"s3://tg-documentation/pytg_current/pytg_current.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import httpx\n",
    "# import base64\n",
    "\n",
    "\n",
    "# def make_headers(conn: TigerGraphConnection):\n",
    "#     tkn = base64.b64encode(f\"{conn.username}:{conn.password}\".encode()).decode()\n",
    "#     headers = {\"Authorization\": f\"Basic {tkn}\"}\n",
    "#     return headers\n",
    "\n",
    "\n",
    "# httpx.get(\n",
    "#     \"http://localhost:8001/GraphRAG_pytgdocs/consistency_status/graphrag\",\n",
    "#     headers=make_headers(conn),\n",
    "#     timeout=None,\n",
    "# )\n",
    "# # conn.ai.forceConsistencyUpdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43masdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in [\"Community\"]:\n",
    "    try:\n",
    "        conn.delVertices(v)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_8a4ea730f21c43abbb58d818b9dd4d5a',\n",
       " 'job_id': 'GraphRAG_pytgdocs.load_documents_content_json_8a4ea730f21c43abbb58d818b9dd4d5a.stream.SupportAI_GraphRAG_pytgdocs_7aed8a01c9c1432b8026ea6c708bf08b.1723490129603',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/GraphRAG_pytgdocs.load_documents_content_json_8a4ea730f21c43abbb58d818b9dd4d5a.stream.SupportAI_GraphRAG_pytgdocs_7aed8a01c9c1432b8026ea6c708bf08b.1723490129603'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for v in [\"Document\", \"Content\", \"DocumentChunk\", \"Entity\",\"ResolvedEntity\",\"Community\"]:\n",
    "# for v in [\"ResolvedEntity\"]:\n",
    "    try:\n",
    "        conn.delVertices(v)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import time\n",
    "\n",
    "print('sleep')\n",
    "time.sleep(3)\n",
    "conn.ai.runDocumentIngest(\n",
    "    res[\"load_job_id\"],\n",
    "    res[\"data_source_id\"],\n",
    "    \"s3://tg-documentation/pytg_current/pytg_current.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gsql(f\"\"\"\n",
    "USE GRAPH {conn.graphname}\n",
    "DROP QUERY ResolveRelationships\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import httpx\n",
    "import logging\n",
    "\n",
    "_ = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "http_timeout = None\n",
    "\n",
    "\n",
    "def make_headers(conn: TigerGraphConnection):\n",
    "    if conn.apiToken is None or conn.apiToken == \"\":\n",
    "        tkn = base64.b64encode(f\"{conn.username}:{conn.password}\".encode()).decode()\n",
    "        headers = {\"Authorization\": f\"Basic {tkn}\"}\n",
    "    else:\n",
    "        headers = {\"Authorization\": f\"Bearer {conn.apiToken}\"}\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def check_vertex_exists(conn, id):\n",
    "    headers = make_headers(conn)\n",
    "    with httpx.Client(timeout=http_timeout) as client:\n",
    "        res = client.get(\n",
    "            f\"{conn.restppUrl}/graph/{conn.graphname}/vertices/Entity/{id}\",\n",
    "            headers=headers,\n",
    "        )\n",
    "\n",
    "        res.raise_for_status()\n",
    "    return res.json()\n",
    "\n",
    "\n",
    "# r = check_vertex_exists(conn, \"asdfTigergraphexception\")\n",
    "# print(json.dumps(r, indent=2), r[\"error\"])\n",
    "r = check_vertex_exists(conn, \"Tigergraphexception\")\n",
    "print(json.dumps(r, indent=2), r[\"error\"])\n",
    "r[\"results\"][0][\"attributes\"][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def check_vertex_has_desc(conn, comm: str):\n",
    "    headers = make_headers(conn)\n",
    "    with httpx.Client(timeout=None) as client:\n",
    "        resp =  client.get(\n",
    "            f\"{conn.restppUrl}/graph/{conn.graphname}/vertices/Community/{comm}\",\n",
    "            headers=headers,\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "\n",
    "    print(json.dumps(resp.json(),indent=2))\n",
    "    desc = resp.json()[\"results\"][0][\"attributes\"][\"description\"]\n",
    "    print(f\">>>*****{comm}:{desc}********\", flush=True)\n",
    "\n",
    "    return len(desc) > 0\n",
    "check_vertex_has_desc(conn,'Value_Property_1_2')\n",
    "conn.upsertVertex(\"Community\",\"Rmse_1_2\",{\n",
    "    \"description\":\"asdf\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_attrs(attributes: dict):\n",
    "    # map attrs\n",
    "    attrs = {}\n",
    "    for k, v in attributes.items():\n",
    "        if isinstance(v, tuple):\n",
    "            attrs[k] = {\"value\": v[0], \"op\": v[1]}\n",
    "        elif isinstance(v, dict):\n",
    "            attrs[k] = {\n",
    "                \"value\": {\"keylist\": list(v.keys()), \"valuelist\": list(v.values())}\n",
    "            }\n",
    "        else:\n",
    "            attrs[k] = {\"value\": v}\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def process_id(v_id: str):\n",
    "    return v_id.replace(\" \", \"_\").replace(\"/\", \"\")\n",
    "\n",
    "\n",
    "def a(vertex_id=\"Post /Requesttoken\"):\n",
    "    vertex_id = process_id(vertex_id)\n",
    "    attributes = {  # attrs\n",
    "        \"description\": [\"test\"],\n",
    "        \"epoch_added\": int(time.time()),\n",
    "    }\n",
    "\n",
    "    vertex_id = vertex_id.replace(\" \", \"_\")\n",
    "    attrs = map_attrs(attributes)\n",
    "    data = json.dumps({\"vertices\": {\"Entity\": {vertex_id: attrs}}})\n",
    "    headers = make_headers(conn)\n",
    "    with httpx.Client(timeout=http_timeout) as client:\n",
    "        res = client.post(\n",
    "            f\"{conn.restppUrl}/graph/{conn.graphname}\", data=data, headers=headers\n",
    "        )\n",
    "\n",
    "        res.raise_for_status()\n",
    "\n",
    "    return res.json()\n",
    "\n",
    "\n",
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "v_id = \"Post_/Requesttoken\"\n",
    "v_id = process_id(v_id)\n",
    "print(v_id)\n",
    "\n",
    "r = check_vertex_exists(conn, v_id)\n",
    "print(json.dumps(r, indent=2), r[\"error\"])\n",
    "r[\"results\"][0][\"attributes\"][\"description\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
