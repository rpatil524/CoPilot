{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# We first create a connection to the database\n",
    "host = os.environ[\"HOST\"]\n",
    "username = os.getenv(\"USERNAME\", \"tigergraph\")\n",
    "password = os.getenv(\"PASS\", \"tigergraph\")\n",
    "conn = TigerGraphConnection(\n",
    "    host=host,\n",
    "    username=username,\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The graph GraphRAG_pytgdocs is created.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname = \"GraphRAG_pytgdocs\"\n",
    "conn.gsql(\"\"\"CREATE GRAPH GraphRAG_pytgdocs()\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conn.getToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_name': 'https://algotesting.i.tgcloud.io',\n",
       " 'schema_creation_status': '\"Using graph \\'GraphRAG_pytgdocs\\'\\\\nSuccessfully created schema change jobs: [add_supportai_schema].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_schema\\\\nDoing schema change on graph \\'GraphRAG_pytgdocs\\' (current version: 0)\\\\nTrying to add local vertex \\'DocumentChunk\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Document\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Concept\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Entity\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Relationship\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'DocumentCollection\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Content\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Community\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'ResolvedEntity\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_CONTENT\\' and its reverse edge \\'reverse_HAS_CONTENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_CHILD_OF\\' and its reverse edge \\'reverse_IS_CHILD_OF\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_HEAD_OF\\' and its reverse edge \\'reverse_IS_HEAD_OF\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_TAIL\\' and its reverse edge \\'reverse_HAS_TAIL\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'DESCRIBES_RELATIONSHIP\\' and its reverse edge \\'reverse_DESCRIBES_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'DESCRIBES_ENTITY\\' and its reverse edge \\'reverse_DESCRIBES_ENTITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'CONTAINS_ENTITY\\' and its reverse edge \\'reverse_CONTAINS_ENTITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'MENTIONS_RELATIONSHIP\\' and its reverse edge \\'reverse_MENTIONS_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_AFTER\\' and its reverse edge \\'reverse_IS_AFTER\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_CHILD\\' and its reverse edge \\'reverse_HAS_CHILD\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_RELATIONSHIP\\' and its reverse edge \\'reverse_HAS_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'CONTAINS_DOCUMENT\\' and its reverse edge \\'reverse_CONTAINS_DOCUMENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'KNN\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RESOLVES_TO\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RESOLVED_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IN_COMMUNITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\n\\\\nGraph GraphRAG_pytgdocs updated to new version 1\\\\nThe job add_supportai_schema completes in 2.434 seconds!\\\\nLocal schema change succeeded.\"',\n",
       " 'index_creation_status': '\"Using graph \\'GraphRAG_pytgdocs\\'\\\\nSuccessfully created schema change jobs: [add_supportai_indexes].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_indexes\\\\nDoing schema change on graph \\'GraphRAG_pytgdocs\\' (current version: 1)\\\\nTrying to add index \\'doc_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_epoch_processing_indexepoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\n\\\\nGraph GraphRAG_pytgdocs updated to new version 2\\\\nThe job add_supportai_indexes completes in 1.932 seconds!\\\\nLocal schema change succeeded.\"'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then add CoPilot's address to the connection. This address\n",
    "# is the host's address where the CoPilot container is running.\n",
    "conn.ai.configureCoPilotHost(\"http://localhost:8000\")\n",
    "conn.ai.initializeSupportAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "sec = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"s3\",\n",
    "    data_source_config={\"aws_access_key\": access, \"aws_secret_key\": sec},\n",
    "    loader_config={\"doc_id_field\": \"url\", \"content_field\": \"content\"},\n",
    "    file_format=\"json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_203b064024e3499ea41b876cc67a85cf',\n",
       " 'job_id': 'GraphRAG_pytgdocs.load_documents_content_json_203b064024e3499ea41b876cc67a85cf.stream.SupportAI_GraphRAG_pytgdocs_5b098715edbd4c878f7425918eb553c0.1721853566538',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/GraphRAG_pytgdocs.load_documents_content_json_203b064024e3499ea41b876cc67a85cf.stream.SupportAI_GraphRAG_pytgdocs_5b098715edbd4c878f7425918eb553c0.1721853566538'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.runDocumentIngest(\n",
    "    res[\"load_job_id\"],\n",
    "    res[\"data_source_id\"],\n",
    "    \"s3://tg-documentation/pytg_current/pytg_current.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_203b064024e3499ea41b876cc67a85cf',\n",
       " 'job_id': 'GraphRAG_pytgdocs.load_documents_content_json_203b064024e3499ea41b876cc67a85cf.stream.SupportAI_GraphRAG_pytgdocs_5b098715edbd4c878f7425918eb553c0.1721853623658',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/GraphRAG_pytgdocs.load_documents_content_json_203b064024e3499ea41b876cc67a85cf.stream.SupportAI_GraphRAG_pytgdocs_5b098715edbd4c878f7425918eb553c0.1721853623658'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for v in [\"Document\", \"Content\", \"DocumentChunk\"]:\n",
    "    try:\n",
    "        conn.delVertices(v)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import time\n",
    "time.sleep(3)\n",
    "conn.ai.runDocumentIngest(\n",
    "    res[\"load_job_id\"],\n",
    "    res[\"data_source_id\"],\n",
    "    \"s3://tg-documentation/pytg_current/pytg_current.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import base64\n",
    "\n",
    "# conn.ai.forceConsistencyUpdate()\n",
    "# url = self.nlqs_host+\"/\"+self.conn.graphname+\"/supportai/forceupdate\"\n",
    "# return self.conn._req(\"GET\", url, authMode=\"pwd\", resKey=None)\n",
    "httpx.get(f\"http://localhost:8000/{conn.graphname}/supportai/forceupdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "print(model.invoke(\"hi\"))\n",
    "structured_llm = model.with_structured_output(Joke)\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "# from langchain_core.pydantic_v1 import BaseModel\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    \"\"\"An answer to the user question along with justification for the answer.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    justification: str\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "model_name = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(model=model_name, temperature=0)\n",
    "# sllm = llm.with_structured_output(AnswerWithJustification)\n",
    "# print(sllm.invoke(\"What weighs more a pound of bricks or a pound of feathers\"))\n",
    "\n",
    "\n",
    "class GraphExtractor:\n",
    "    def __init__(self):\n",
    "        self.transformer = LLMGraphTransformer(\n",
    "            llm=llm,\n",
    "            node_properties=[\"description\"],\n",
    "            relationship_properties=[\"description\"],\n",
    "        )\n",
    "\n",
    "    def extract(self, text):\n",
    "        doc = Document(page_content=text)\n",
    "        graph_docs = self.transformer.convert_to_graph_documents([doc])\n",
    "        return graph_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "\"\"\"\n",
    "ge = GraphExtractor()\n",
    "\n",
    "docs = ge.extract(text)\n",
    "for d in docs:\n",
    "    for n in d.nodes:\n",
    "        print(n)\n",
    "    for r in d.relationships:\n",
    "        print(r)\n",
    "# print(f\"Nodes:{docs[0].nodes}\")\n",
    "# print(f\"Relationships:{docs[0].relationships}\")\n",
    "# docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
