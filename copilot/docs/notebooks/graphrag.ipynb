{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyTigerGraph import TigerGraphConnection\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# We first create a connection to the database\n",
    "host = os.environ[\"HOST\"]\n",
    "username = os.getenv(\"USERNAME\", \"tigergraph\")\n",
    "password = os.getenv(\"PASS\", \"tigergraph\")\n",
    "conn = TigerGraphConnection(\n",
    "    host=host,\n",
    "    username=username,\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The graph GraphRAG_pytgdocs is created.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname = \"GraphRAG_pytgdocs\"\n",
    "conn.gsql(\"\"\"CREATE GRAPH GraphRAG_pytgdocs()\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conn.getToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'host_name': 'https://algotesting.i.tgcloud.io',\n",
       " 'schema_creation_status': '\"Using graph \\'GraphRAG_pytgdocs\\'\\\\nSuccessfully created schema change jobs: [add_supportai_schema].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_schema\\\\nDoing schema change on graph \\'GraphRAG_pytgdocs\\' (current version: 0)\\\\nTrying to add local vertex \\'DocumentChunk\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Document\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Concept\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Entity\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Relationship\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'DocumentCollection\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Content\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'Community\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local vertex \\'ResolvedEntity\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_CONTENT\\' and its reverse edge \\'reverse_HAS_CONTENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_CHILD_OF\\' and its reverse edge \\'reverse_IS_CHILD_OF\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_HEAD_OF\\' and its reverse edge \\'reverse_IS_HEAD_OF\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_TAIL\\' and its reverse edge \\'reverse_HAS_TAIL\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'DESCRIBES_RELATIONSHIP\\' and its reverse edge \\'reverse_DESCRIBES_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'DESCRIBES_ENTITY\\' and its reverse edge \\'reverse_DESCRIBES_ENTITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'CONTAINS_ENTITY\\' and its reverse edge \\'reverse_CONTAINS_ENTITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'MENTIONS_RELATIONSHIP\\' and its reverse edge \\'reverse_MENTIONS_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IS_AFTER\\' and its reverse edge \\'reverse_IS_AFTER\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_CHILD\\' and its reverse edge \\'reverse_HAS_CHILD\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'HAS_RELATIONSHIP\\' and its reverse edge \\'reverse_HAS_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'CONTAINS_DOCUMENT\\' and its reverse edge \\'reverse_CONTAINS_DOCUMENT\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RELATIONSHIP\\' and its reverse edge \\'reverse_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RESOLVES_TO\\' and its reverse edge \\'reverse_RESOLVES_TO\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'RESOLVED_RELATIONSHIP\\' and its reverse edge \\'reverse_RESOLVED_RELATIONSHIP\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add local edge \\'IN_COMMUNITY\\' and its reverse edge \\'reverse_IN_COMMUNITY\\' to the graph \\'GraphRAG_pytgdocs\\'.\\\\n\\\\nGraph GraphRAG_pytgdocs updated to new version 1\\\\nThe job add_supportai_schema completes in 2.208 seconds!\\\\nLocal schema change succeeded.\"',\n",
       " 'index_creation_status': '\"Using graph \\'GraphRAG_pytgdocs\\'\\\\nSuccessfully created schema change jobs: [add_supportai_indexes].\\\\nWARNING: When modifying the graph schema, reinstalling all affected queries is required, and the duration of this process may vary based on the number and complexity of the queries. To skip query reinstallation, you can run with the \\'-N\\' option, but manual reinstallation of queries will be necessary afterwards.\\\\nKick off schema change job add_supportai_indexes\\\\nDoing schema change on graph \\'GraphRAG_pytgdocs\\' (current version: 1)\\\\nTrying to add index \\'doc_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_epoch_processing_indexepoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Document\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'doc_chunk_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'DocumentChunk\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_added_index\\' on the attribute \\'epoch_added\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_processing_index\\' on the attribute \\'epoch_processing\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\nTrying to add index \\'concept_epoch_processed_index\\' on the attribute \\'epoch_processed\\' of local vertex \\'Concept\\' on the graph \\'GraphRAG_pytgdocs\\'.\\\\n\\\\nGraph GraphRAG_pytgdocs updated to new version 2\\\\nThe job add_supportai_indexes completes in 3.025 seconds!\\\\nLocal schema change succeeded.\"'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then add CoPilot's address to the connection. This address\n",
    "# is the host's address where the CoPilot container is running.\n",
    "conn.ai.configureCoPilotHost(\"http://localhost:8000\")\n",
    "conn.ai.initializeSupportAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = os.environ[\"AWS_ACCESS_KEY_ID\"]\n",
    "sec = os.environ[\"AWS_SECRET_ACCESS_KEY\"]\n",
    "res = conn.ai.createDocumentIngest(\n",
    "    data_source=\"s3\",\n",
    "    data_source_config={\"aws_access_key\": access, \"aws_secret_key\": sec},\n",
    "    loader_config={\"doc_id_field\": \"url\", \"content_field\": \"content\"},\n",
    "    file_format=\"json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_b89acfebac9e4fb98efd20a49659808e',\n",
       " 'job_id': 'GraphRAG_pytgdocs.load_documents_content_json_b89acfebac9e4fb98efd20a49659808e.stream.SupportAI_GraphRAG_pytgdocs_5698bff74d844534901cba9e1b3d55bf.1722466964295',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/GraphRAG_pytgdocs.load_documents_content_json_b89acfebac9e4fb98efd20a49659808e.stream.SupportAI_GraphRAG_pytgdocs_5698bff74d844534901cba9e1b3d55bf.1722466964295'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.ai.runDocumentIngest(\n",
    "    res[\"load_job_id\"],\n",
    "    res[\"data_source_id\"],\n",
    "    \"s3://tg-documentation/pytg_current/pytg_current.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200 OK]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import httpx\n",
    "import base64\n",
    "\n",
    "\n",
    "def make_headers(conn: TigerGraphConnection):\n",
    "    tkn = base64.b64encode(f\"{conn.username}:{conn.password}\".encode()).decode()\n",
    "    headers = {\"Authorization\": f\"Basic {tkn}\"}\n",
    "    return headers\n",
    "\n",
    "\n",
    "httpx.get(\n",
    "    \"http://localhost:8001/GraphRAG_pytgdocs/consistency_status/graphrag\",\n",
    "    headers=make_headers(conn),\n",
    ")\n",
    "# conn.ai.forceConsistencyUpdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43masdf\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'asdf' is not defined"
     ]
    }
   ],
   "source": [
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_name': 'load_documents_content_json_b89acfebac9e4fb98efd20a49659808e',\n",
       " 'job_id': 'GraphRAG_pytgdocs.load_documents_content_json_b89acfebac9e4fb98efd20a49659808e.stream.SupportAI_GraphRAG_pytgdocs_5698bff74d844534901cba9e1b3d55bf.1722531204658',\n",
       " 'log_location': '/home/tigergraph/tigergraph/log/kafkaLoader/GraphRAG_pytgdocs.load_documents_content_json_b89acfebac9e4fb98efd20a49659808e.stream.SupportAI_GraphRAG_pytgdocs_5698bff74d844534901cba9e1b3d55bf.1722531204658'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for v in [\"Document\", \"Content\", \"DocumentChunk\", \"Entity\",\"ResolvedEntity\"]:\n",
    "# for v in [\"ResolvedEntity\"]:\n",
    "    try:\n",
    "        conn.delVertices(v)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "import time\n",
    "\n",
    "time.sleep(3)\n",
    "conn.ai.runDocumentIngest(\n",
    "    res[\"load_job_id\"],\n",
    "    res[\"data_source_id\"],\n",
    "    \"s3://tg-documentation/pytg_current/pytg_current.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gsql(f\"\"\"\n",
    "USE GRAPH {conn.graphname}\n",
    "DROP QUERY ResolveRelationships\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'deleted_vertices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m conn\u001b[38;5;241m.\u001b[39mgetToken()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunity\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# for v in [\"ResolvedEntity\"]:\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelVertices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/ml/lib/python3.11/site-packages/pyTigerGraph/pyTigerGraphVertex.py:688\u001b[0m, in \u001b[0;36mpyTigerGraphVertex.delVertices\u001b[0;34m(self, vertexType, where, limit, sort, permanent, timeout)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    686\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isFirst \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(timeout)\n\u001b[0;32m--> 688\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delete\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdeleted_vertices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger\u001b[38;5;241m.\u001b[39mlevel \u001b[38;5;241m==\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG:\n\u001b[1;32m    691\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(ret))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'deleted_vertices'"
     ]
    }
   ],
   "source": [
    "conn.graphname = \"Cora\"\n",
    "conn.getToken()\n",
    "for v in [\"Community\"]:\n",
    "    # for v in [\"ResolvedEntity\"]:\n",
    "    conn.delVertices(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import httpx\n",
    "import logging\n",
    "\n",
    "_ = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "http_timeout = None\n",
    "\n",
    "\n",
    "def make_headers(conn: TigerGraphConnection):\n",
    "    if conn.apiToken is None or conn.apiToken == \"\":\n",
    "        tkn = base64.b64encode(f\"{conn.username}:{conn.password}\".encode()).decode()\n",
    "        headers = {\"Authorization\": f\"Basic {tkn}\"}\n",
    "    else:\n",
    "        headers = {\"Authorization\": f\"Bearer {conn.apiToken}\"}\n",
    "\n",
    "    return headers\n",
    "\n",
    "\n",
    "def check_vertex_exists(conn, id):\n",
    "    headers = make_headers(conn)\n",
    "    with httpx.Client(timeout=http_timeout) as client:\n",
    "        res = client.get(\n",
    "            f\"{conn.restppUrl}/graph/{conn.graphname}/vertices/Entity/{id}\",\n",
    "            headers=headers,\n",
    "        )\n",
    "\n",
    "        res.raise_for_status()\n",
    "    return res.json()\n",
    "\n",
    "\n",
    "# r = check_vertex_exists(conn, \"asdfTigergraphexception\")\n",
    "# print(json.dumps(r, indent=2), r[\"error\"])\n",
    "r = check_vertex_exists(conn, \"Tigergraphexception\")\n",
    "print(json.dumps(r, indent=2), r[\"error\"])\n",
    "r[\"results\"][0][\"attributes\"][\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_attrs(attributes: dict):\n",
    "    # map attrs\n",
    "    attrs = {}\n",
    "    for k, v in attributes.items():\n",
    "        if isinstance(v, tuple):\n",
    "            attrs[k] = {\"value\": v[0], \"op\": v[1]}\n",
    "        elif isinstance(v, dict):\n",
    "            attrs[k] = {\n",
    "                \"value\": {\"keylist\": list(v.keys()), \"valuelist\": list(v.values())}\n",
    "            }\n",
    "        else:\n",
    "            attrs[k] = {\"value\": v}\n",
    "    return attrs\n",
    "\n",
    "\n",
    "def process_id(v_id: str):\n",
    "    return v_id.replace(\" \", \"_\").replace(\"/\", \"\")\n",
    "\n",
    "\n",
    "def a(vertex_id=\"Post /Requesttoken\"):\n",
    "    vertex_id = process_id(vertex_id)\n",
    "    attributes = {  # attrs\n",
    "        \"description\": [\"test\"],\n",
    "        \"epoch_added\": int(time.time()),\n",
    "    }\n",
    "\n",
    "    vertex_id = vertex_id.replace(\" \", \"_\")\n",
    "    attrs = map_attrs(attributes)\n",
    "    data = json.dumps({\"vertices\": {\"Entity\": {vertex_id: attrs}}})\n",
    "    headers = make_headers(conn)\n",
    "    with httpx.Client(timeout=http_timeout) as client:\n",
    "        res = client.post(\n",
    "            f\"{conn.restppUrl}/graph/{conn.graphname}\", data=data, headers=headers\n",
    "        )\n",
    "\n",
    "        res.raise_for_status()\n",
    "\n",
    "    return res.json()\n",
    "\n",
    "\n",
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "v_id = \"Post_/Requesttoken\"\n",
    "v_id = process_id(v_id)\n",
    "print(v_id)\n",
    "\n",
    "r = check_vertex_exists(conn, v_id)\n",
    "print(json.dumps(r, indent=2), r[\"error\"])\n",
    "r[\"results\"][0][\"attributes\"][\"description\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
